# -*- coding: utf-8 -*-
"""Classificador.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GHuYPtDcYqU-Tf5gWyEh17PkbTHyGpQp
"""

import sys
import random
import numpy as np
import pandas as pd
import skimage.morphology as morph
from sklearn.model_selection import StratifiedKFold
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score
from skimage.feature import local_binary_pattern, hog
from sklearn.ensemble import RandomForestClassifier
from google.colab import drive
import matplotlib.pyplot as plt
import pickle
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/Shared drives/Equipe amigos/2020.1/PDI/bancodedados.csv', sep=",", header=0)
df

def median_filter(img, filterSize=3):
  filterRadius = filterSize//2
  img_pad = np.pad(img, ((filterRadius, ),(filterRadius, )), 'edge')


  filtered_img = np.zeros(img_pad.shape)
  for x in np.arange(filterRadius, img_pad.shape[0]-filterRadius+1):
    for y in np.arange(filterRadius, img_pad.shape[1]-filterRadius+1):
      med_region = np.median(img_pad[x-filterRadius:x+filterRadius+1, y-filterRadius:y+filterRadius+1])
      filtered_img[x,y] = med_region

  return filtered_img[filterRadius:img_pad.shape[0]-filterRadius, filterRadius:img_pad.shape[1]-filterRadius]

def preprocessing(img):
  aux = np.reshape(img, (150, 150))
  aux = median_filter(aux)
  aux = aux - morph.erosion(aux, morph.disk(2))

  return aux

def get_mean_accuracy(model, X, y):
  
  random.seed(10)
  accuracy = 0.0
  cv = StratifiedKFold(n_splits=10, shuffle=False)


  for train_index, test_index in cv.split(X, y):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]
    model.fit(X_train, y_train.reshape(-1))
    y_pred = model.predict(X_test)

    accuracy += accuracy_score(y_test.reshape(-1), y_pred)
  return float(accuracy/10)

#Separando dados e classes
data = df.iloc[:, :-1].to_numpy()
classes = df.iloc[:,-1].to_numpy()
data_img = []

for i in range(data.shape[0]):
  data_img.append(preprocessing(data[i]))

lbp = []

for i in range(len(data_img)):
  aux = local_binary_pattern(data_img[i], 8, 1)
  hist, bins = np.histogram(aux, int(aux.max() + 1), density=True)
  lbp.append(hist)

hog_v = []
for i in range(len(data_img)): 
  hog_v.append(hog(data_img[i], feature_vector=True))

data_features = np.empty(len(data_img), dtype=np.ndarray)
for i in range(len(data_img)):
  data_features[i] = np.append(lbp[i],hog_v[i])

data_features = np.vstack(data_features)

print(data_features)

mlp = MLPClassifier(random_state=10)

acc = get_mean_accuracy(mlp, data_features, classes)
print(acc)

rf = RandomForestClassifier(random_state=0)
acc2 = get_mean_accuracy(rf, data_features, classes)
print(acc2)

filename = '/content/drive/Shared drives/Equipe amigos/2020.1/PDI/finalized_model.sav'
pickle.dump(mlp, open(filename, 'wb'))